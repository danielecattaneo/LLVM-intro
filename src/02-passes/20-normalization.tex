% !TEX root = main.tex

\section{Normalization Passes}


\begin{frame}{Canonicalizing Pass Input}
We will see the following passes:

\begin{table}
\centering
\begin{tabular}{cc}
\toprule

\multicolumn{1}{c}{\textbf{Pass}}    &
\multicolumn{1}{c}{\textbf{Switch}} \\

\midrule

Variable promotion  &
\texttt{mem2reg}   \\

Loop simplification &
\texttt{loop-simplify} \\

Loop-closed SSA  &
\texttt{lcssa}  \\

Induction variable simplification  &
\texttt{indvars}                  \\

\bottomrule
\end{tabular}
\end{table}

They are \alert{normalization} passes:

\begin{itemize}
\item they convert the code into a canonical form
\end{itemize}
\end{frame}


\subsection{Variable Promotion}


\begin{frame}{Variable Promotion}
\begin{center}
One of the most difficult things in compilers is\\\alert{handling memory accesses}.
\end{center}
\vfill
\begin{block}{Plain SAXPY (Scalar $ax + y$)}
\centering
\llvminput[\tt\footnotesize]{snippet/plain-saxpy.ll}
\end{block}
\end{frame}


\begin{frame}{Variable Promotion}{Simplifying Representation}
In the SAXPY kernel all the variables are \llvminline{alloca}ted on the stack!
\begin{itemize}
\item Function arguments included!
\end{itemize}

\vfill
They are allocated like that because the compiler follows a \alert{conservative} approach:
\begin{itemize}
\item an instruction could take the address of one of the variables...
\end{itemize}

\vfill
However, complex representations make optimizations more difficult:
\begin{itemize}
\item suppose you want to compute the \cinline{a*x+y} expression using only \alert{one}
      instruction (aka FMA4)
\item hard to detect due to \llvminline{load} and \llvminline{store}
\end{itemize}
\end{frame}


\begin{frame}{Variable Promotion}{Using Memory Only When Necessary}
To limit the number of instruction accessing memory we need to eliminate \llvminline{load} and \llvminline{store}
\begin{itemize}
\item achieved by \alert{promoting} variables from memory to registers
\end{itemize}

\vfill
Inside the LLVM-IR:
\begin{description}
\item[memory] Stack allocations \\
              \llvminline{\%1 = alloca float, align 4}
\item[register] SSA variables \\
							\llvminline{\%a}
\end{description}

\vfill
The \texttt{mem2reg} pass focus on:
\begin{itemize}
\item eliminating \llvminline{alloca} used only by \llvminline{load} and
      \llvminline{store} instructions
\end{itemize}

Also available as a utility function:
\begin{itemize}
\item \cppinline{llvm::PromoteMemToReg}\\
\begin{itemize}
\item see \texttt{llvm/Transforms/Utils/PromoteMemToReg.h}
\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}{Variable Promotion}{Example on simplified code}
\begin{columns}[t]
\column{.45\textwidth}
\begin{block}{Starting Point}
\llvminput[\tt\footnotesize]{snippet/saxpy.ll}
\end{block}

(copy propagation is performed transparently by the compiler)

\column{.45\textwidth}
\begin{block}{Promoting \llvminline{alloca}}
\llvminput[\tt\footnotesize]{snippet/mem2reg-saxpy.ll}
\end{block}

\begin{block}{After Copy-propagation}
\llvminput[\tt\footnotesize]{snippet/mem2reg-copy-saxpy.ll}
\end{block}

\end{columns}
\end{frame}


\subsection{Loop Simplification}


\begin{frame}{Loops}
\begin{center}
There are several kind of loops:

\begin{columns}[t]
\column{.30\textwidth}
\begin{block}{\cinline{do}-\cinline{while} Loops}
\centering
\input{img/do-while-loop.tex}
\end{block}

\column{.30\textwidth}
\begin{block}{\cinline{while} Loops}
\centering
\input{img/while-loop.tex}
\end{block}

\column{.30\textwidth}
\begin{block}{Irreducible Loops}
\centering
\input{img/irreducible-loop.tex}
\end{block}
\end{columns}

\bigskip
LLVM focuses on one class of loop:\\
\alert{Natural Loops}
\end{center}
\end{frame}


\begin{frame}{Natural Loops}
A natural loop:

\begin{itemize}
\item has only one entry node -- the \emph{header}
\item there is a back edge that enters the loop header
\end{itemize}

\vfill
Under this definition:

\begin{itemize}
\item the irreducible loop example is not a natural loop
\item since LLVM consider only natural loops, the irreducible loop example \alert{is not
      recognized} as a loop
\end{itemize}
\end{frame}


\begin{frame}{Loop Terminology}
Loops are defined starting from the back-edges:

\begin{columns}[t]

\column{.59\textwidth}
\begin{description}
\item[back-edge] edge entering loop header: $(3,1)$
\item[header] loop entry node: $1$
\item[body] nodes that can reach back-edge source node ($3$) without passing
            from back-edge target node ($1$) plus back-edge target node:
            $\{1 ,2, 3\}$
\end{description}

\column{.32\textwidth}
\begin{block}{\small A loop}
\input{img/loop-nodes.tex}
\end{block}

\end{columns}

\begin{description}
\item[exiting] nodes with a successor outside the loop: $\{1, 3\}$
\item[exit] nodes with a predecessor inside the loop: $\{4, 5\}$
\end{description}
\end{frame}


\begin{frame}{Loop Simplify}

Natural loops are

\begin{itemize}
\item easy to \alert{identify}
\item not really analysis/optimization friendly!
\end{itemize}

\vfill
The \texttt{loop-simplify} pass normalizes natural loops:

\begin{columns}[t]
\column{.50\textwidth}
\begin{description}
\item[pre-header] ensures the \alert{loop header} has \alert{a single entry edge}
\item[latch] ensures the loop has \alert{a single back-edge}
\item[exit-block] ensures \alert{exits dominated} by loop \alert{header}
\end{description}

\column{.40\textwidth}
\vspace{-1em}
\begin{block}{Pre-header Insertion}
\centering
\input{img/pre-header.tex}
\end{block}
\end{columns}
\end{frame}


\begin{frame}{Loop Simplify}{Example}
\vspace{-1.5em}
\begin{columns}[t]
\column{.45\textwidth}
\begin{block}{Latch Insertion}
\centering
\input{img/latch.tex}
\end{block}

\column{.45\textwidth}
\begin{block}{Exit-block Insertion}
\centering
\input{img/exit-block.tex}
\end{block}
\end{columns}
\bigskip
\begin{itemize}
\item pre-header always executed before entering the loop
\item latch always executed before starting a new iteration
\item exit-blocks executed only after exiting the loop
\end{itemize}
\end{frame}


\subsection{Loop-closed SSA}


\begin{frame}{Loop-closed SSA}
Loop representation can be further normalized:

\begin{itemize}
\item \texttt{loop-simplify} normalizes the \alert{shape} of the loop \emph{(control flow)}
\item it does not involve the instructions in the loop \emph{(data flow)}
\end{itemize}

\vfill
Keeping SSA form is expensive with loops:
\begin{itemize}
\item Any optimization involving an SSA variable \alert{defined inside the loop}, and \alert{used
outside the loop}, causes a ripple effect!
\end{itemize}
\vfill
The \texttt{lcssa} transformation is the solution:
\begin{itemize}
\item inserts \llvminline{phi} instructions at loop boundaries
\item now, optimizations performed inside the loop do not affect the code outside of it
\end{itemize}
\end{frame}


\begin{frame}{Loop-closed SSA}{Example}
\begin{block}{Linear Search}
\centering
\cinput{snippet/lcssa.c}
\end{block}

\vfill
\begin{center}
The example is trivial, this transformation is mostly useful for \emph{large loop bodies}.
\end{center}
\end{frame}


\begin{frame}{Loop-closed SSA}{Example}
\begin{block}{Before LCSSA}
\centering
\llvminput[\scriptsize\tt]{snippet/before-lcssa.ll}
\end{block}
\vspace{\baselineskip}
\vfill
\end{frame}


\begin{frame}{Loop-closed SSA}{Example}
\begin{block}{After LCSSA}
\centering
\llvminput[\scriptsize\tt]{snippet/after-lcssa.ll}
\end{block}
\vfill
\end{frame}


\subsection{Induction variable simplification}


\begin{frame}{Induction Variables}
Some loop variables are \emph{special}:

\begin{itemize}
\item e.g. counters
\end{itemize}

\vfill
The generalization of this intuition are \alert{induction variables}:

\begin{itemize}
\item \cinline{foo} is a \textbf{loop induction variable}\\
		  if its successive values form
      an arithmetic progression:

      \begin{center}
      \cinline{foo = bar * baz + biz}
      \end{center}

      where:
      \cinline{bar}, \cinline{biz} are loop-invariant~\footnote{Constants inside the loop},\\
      \hphantom{where: }\cinline{baz} is an induction variable
\item \cinline{foo} is a \textbf{canonical induction variable}\\if it is always
      incremented by a constant amount:

      \begin{center}
      \cinline{foo = foo + biz}
      \end{center}

      where \cinline{biz} is loop-invariant
\end{itemize}
\end{frame}


\begin{frame}{Induction Variable Simplification}
Canonical induction variables are often used to \alert{drive} loop execution.

\vfill

Given a loop, the \texttt{indvars} pass tries to transform its induction variables
into \alert{canonical} induction variables.
\begin{itemize}
\item It also transforms loop exit conditions in simple inequalities
\item Definition of other variables derived from the induction variables
      are moved outside the loop if used there
\end{itemize}

\vfill
LLVM defines canonical induction variables as:

\begin{itemize}
\item initialized to \llvminline{0}
\item incremented by \llvminline{1} at each loop iteration
\end{itemize}
\end{frame}


\subsection{Recap}


\begin{frame}{Normalization}{Wrap-up}
``Standard'' running order:

\begin{enumerate}
\item \texttt{mem2reg}: limits use of memory
\item \texttt{loop-simplify}: canonicalizes loops
	\begin{itemize}
	\item Improved detection of a lot of standard patterns!
	\end{itemize}
\item \texttt{lcssa}: keeps effects of subsequent loop optimizations local\\
      \hphantom{\texttt{lcssa}: }limits overhead of maintaining SSA form
\item \texttt{indvars}: normalizes induction variables\\
			\hphantom{\texttt{indvars}: }simplifies and highlightsthe loop condition
\end{enumerate}

\vfill
For more normalization passes:

\begin{itemize}
\item try running \texttt{opt -help}
\end{itemize}
\end{frame}

