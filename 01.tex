\documentclass[10pt,mathserif]{beamer}
\input{packages}

\author{Daniele Cattaneo}
\institute{Politecnico di Milano}
\date{03-05-2019}
\title{Introduction to the LLVM compiler framework}
\newcommand{\customdata}{Daniele Cattaneo <daniele.cattaneo@polimi.it>}

\AtBeginSection[]
{
\begin{frame}{Contents}
\tableofcontents[currentsection]
\end{frame}
}


\begin{document}

\begin{frame}
\maketitle
\begin{center}
\itshape\scriptsize These slides were originally written by
                    Michele Scandale, Ettore Speziale and Stefano Cherubin for the 
                    ``Code Transformation and Optimization'' course.
\end{center}
\end{frame}


\section{Introduction}


\begin{frame}{Compilers and compilers}
\begin{center}
Not all compilers are the same... The traditional distinction was:

\begin{columns}[t]

\column{.40\textwidth}
\begin{block}{Toy Compiler}
\begin{itemize}
\item small codebase
\item easy to modify
\item limited capabilities
\end{itemize}
\end{block}

\column{.50\textwidth}
\begin{block}{Production-Quality Compiler}
\begin{itemize}
\item huge codebase
\item hard to modify
\item produces high-quality code
\end{itemize}
\end{block}

\end{columns}
\bigskip
Working with a production-quality compiler is \emph{initially} \alert{hard}...\\
\medskip
...however it provides a huge set of tools that toy compilers \alert{miss}!
\end{center}
\end{frame}


\begin{frame}{LLVM: Low Level Virtual Machine}
\begin{center}
Initially started as a small research project at Urbana-Champaign.\\
\medskip
Now it has grown to a huge size...
\end{center}

\begin{itemize}
\item Key technology in the \alert{industry}: AMD, Apple, Google, Intel, NVIDIA...
\item Still intensively used in \alert{research} about compilers
\end{itemize}
\end{frame}


\begin{frame}{GCC vs LLVM}
\begin{center}
\textbf{LLVM}~\cite{LOCAL:www/llvm} is Open Source\\
\medskip
If you are familiar with Linux you might have used \textbf{GCC}~\cite{LOCAL:www/gcc}...\\
\bigskip
GCC is older than LLVM\\
\bigskip
\bigskip
\vbox{
\begin{varwidth}{6cm}
\begin{itemize}
\item[$\Rightarrow$] GCC produces better code
\item[$\Rightarrow$] LLVM is generally faster
\item[$\Rightarrow$] LLVM is more modular and \emph{clean}
\end{itemize}
\end{varwidth}
}
\end{center}
\end{frame}


\section{Compiler organization}
\begin{frame}{Compiler pipeline}
\begin{center}
Typically a compiler is a \alert{pipeline}.\\
\bigskip
Advantages of the pipeline model:\\
\medskip
\begin{varwidth}{0.8\textwidth}
\begin{itemize}
\item \alert{simplicity} -- read something, produce something
\item \alert{locality} -- no superfluous state
\end{itemize}
\end{varwidth}
\\
\bigskip
Complexity lies on \alert{chaining} together stages.
\end{center}
\end{frame}


\begin{frame}{Compiler pipeline}{Internal pipelines}
\begin{center}
High-level pipeline structure of a compiler:\\
\begin{figure}
\centering
\input{img/01/compiler-structure.tex}
\end{figure}
\medskip
There are three main components:

\begin{description}
\item[Front-end] \alert{translate} a source file into the intermediate representation
\item[Middle-end] \alert{analyze} the intermediate representation, \alert{optimize}
                  it
\item[Back-end] \alert{generate} target machine assembly from the intermediate
                representation
\end{description}
\end{center}
\end{frame}


\begin{frame}{The LLVM compiler pipeline}
\begin{center}
We will consider only the \emph{middle-end}.\\
{\small Same concepts are valid also for \{front,back\}-end.}\\
\bigskip
\begin{description}[Pass Manager]
\item[IR] (a.k.a. Intermediate Representation) the \alert{language} used in the
          middle-end
\item[Pass] a \alert{pipeline stage}\\
a Pass may have \alert{dependencies} on other Passes.
\item[Pass Manager] component that \alert{schedules} passes according to their \alert{dependencies} and \alert{executes} them\\
\emph{(builds the pipeline)}
\end{description}
\end{center}
\end{frame}


\begin{frame}{First insights}
A compiler is \alert{complex}:

\begin{itemize}
\item passes are the \alert{elementary unit of work}
\item Pass Manager must be \alert{advised} about pass chaining
\item pipeline shapes are \alert{not fixed} -- they can change from one compiler
      execution to another\\
      {\small e.g. optimized/not optimized builds, compiler options, ...}
\end{itemize}
\end{frame}


\begin{frame}{A word of warning!}
\begin{center}
{\large 
Compilers must be \alert{conservative}:\\
\smallskip
$\Downarrow$\\
\smallskip
All passes \alert{must preserve the program semantics}\\
\smallskip
$\Downarrow$\\
\smallskip
Compiler passes must be designed \alert{very carefully}!\\
}
\end{center}
\end{frame}


\section{Algorithm design}
\begin{frame}{Classical Algorithm Design}
In algorithm design, a good approach is the following:
\begin{enumerate}
\item study the problem
\item make some example
\item identify the \alert{common case}
\item derive the algorithm for the common case
\item add handling for \alert{corner cases}
\item improve performancing \alert{optimizing the common case}
\end{enumerate}

\vfill
Weakness of the approach:
\begin{itemize}
\item \alert{corner cases} -- a \emph{correct} algorithm \textbf{must} consider \emph{all the corner cases}!
\end{itemize}
\end{frame}


\begin{frame}{Compiler Algorithm Design}{Be Conservative}
\begin{center}
Corner cases are difficult to handle, but they cannot be ignored\\
\smallskip
{\small Compiler algorithms must be \alert{proven} to preserve\\
program semantic \alert{at all times}}\\
\bigskip
As an aid, a \emph{standard methodology} is employed.\\
\bigskip
Compiler algorithms are built combining \alert{three} kinds of passes:\\
\medskip
Analysis, Optimization, Normalization\\
\bigskip
\pause
We now consider a simple example: \emph{loop hoisting}.
\end{center}
\end{frame}


\begin{frame}{Loop Hoisting}
It is a transformation that:
\begin{itemize}
\item looks for statements (inside a loop) not depending on the loop state
\item move them outside the loop body
\end{itemize}

\begin{columns}[t]
\column{.45\textwidth}
\begin{block}{Loop Hoisting -- Before}
\centering
\cinput{snippet/01/loop-hoisting-before.c}
\end{block}

\column{.45\textwidth}
\begin{block}{Loop Hoisting -- After}
\centering
\cinput{snippet/01/loop-hoisting-after.c}
\end{block}
\end{columns}
\end{frame}


\begin{frame}{Loop Hoisting}{Focus on the Transformation}
\begin{block}{The general idea:}
\begin{itemize}
\item move ``good'' statement outside of the loop
\end{itemize}
\end{block}

This \alert{pass} modifies the code: \\
thus it is an \alert{optimization pass}.

It needs to know:
\begin{itemize}
\item which pieces of code are loops
\item which statements are ``good'' statements
\end{itemize}

These are the \alert{analyses}, which belong to their own passes:

\begin{itemize}
\item detecting loops in the program
\item detecting loop-independent statements
\end{itemize}

When registering loop hoisting, also declare needed analysis:

\begin{itemize}
\item pipeline automatically built: \alert{analysis $\rightarrow$ optimization}
\end{itemize}
\end{frame}


\begin{frame}{Loop Hoisting}{Proving Program Semantic Preservation}
The \alert{proof} is trivial:

\begin{itemize}
\item transformation is correct if analysis are correct, but \ldots
\item \ldots usually analysis are built starting from other analysis already
      implemented inside the compiler
\end{itemize}

\vfill
You have to prove that combining all analysis information gives you a
correct view of the code:

\begin{itemize}
\item analysis information cannot induce optimization passes applying a
      transformation not preserving program semantic
\end{itemize}
\end{frame}

\begin{frame}{Loop Hoisting}{More Loops}
We have spoken about loops, but which kind of loop?

\begin{itemize}
\item \cinline{do-while} loops?
\item \cinline{while} loop?
\item \cinline{for} loops?
\end{itemize}

We have seen loop hoisting on:

\begin{itemize}
\item \cinline{do-while} loops
\end{itemize}

What about other kinds of loops?

\begin{itemize}
\item they must be normalized -- i.e. transformed to \cinline{do-while} loops
\end{itemize}

\alert{Normalization passes} do that:

\begin{itemize}
\item before running loop hoisting, you must tell to the pass manager that loop
      normalization must be run before
\end{itemize}

This allows to recognize more loops, thus potentially
\alert{improving optimization impact}!
\end{frame}

\begin{frame}{Compiler Algorithm Design}{A methodology}
You have to:

\begin{enumerate}
\item analyze the problem
\item make some examples
\item detect the common case
\item declare the \alert{input format}
\item declare \alert{analysis} you need
\item design an \alert{optimization} pass
\item proof its \alert{correctness}
\item improve algorithm perfomance by acting on common case -- the only
      considered up to now. Please notice that corner cases are not considered
      -- just do not try to optimize the corner cases
\item improve the effectiveness of the algorithm by adding
      \alert{normalization passes}
\end{enumerate}
\end{frame}

\section{Inside LLVM}
\begin{frame}{Terminology}{Speaking About LLVM IR}
LLVM IR comes with 3 different flavours:

\begin{description}
\item[assembly] human-readable format
\item[bitcode] binary on-disk machine-oriented format
\item[in-memory] binary in-memory format, used during compilation process
\end{description}

All formats have the same expressiveness!

\vfill
File extensions:

\begin{description}
\item[.ll] for assembly files
\item[.bc] for bitcode files
\end{description}
\end{frame}

\begin{frame}{Tools}{C Language Family Front-end}
Writing LLVM assembly by hand is unfeasible:

\begin{itemize}
\item different front-ends available for LLVM
\item use Clang~\cite{LOCAL:www/clang} for the C family
\end{itemize}

The clang driver is compatible with GCC:

\begin{itemize}
\item $\approx$ same command line options
\end{itemize}

\vfill
To generate LLVM IR:

\begin{description}
\item[assembly] \texttt{\smaller clang -emit-llvm -S -o out.ll in.c}
\item[bitcode] \texttt{\smaller  clang -emit-llvm -o out.bc in.c}
\end{description}

It can also generate native code starting from LLVM assembly or LLVM bitcode --
like compiling an assembly file with GCC
\end{frame}

\begin{frame}{Tools}{Playing with LLVM Passes}
LLVM IR can be manipulated using \texttt{\smaller opt}:

\begin{itemize}
\item read an input file
\item run specified LLVM passes on it
\item respecting user-provided order
\end{itemize}

\vfill
Useful passes:

\begin{itemize}
\item print CFG with \texttt{\smaller opt -view-cfg input.ll}
\item print dominator tree with \texttt{\smaller opt -view-dom input.ll}
\item \ldots
\end{itemize}

Pass chaining:

\begin{itemize}
\item run \emph{mem2reg}, then view the CFG with \\
\texttt{\smaller opt -mem2reg -view-cfg input.ll}
\item potentially different results using different option order (\alert{phase/stage ordering})
\end{itemize}
\end{frame}

\begin{frame}{Pass Hierarchy}
LLVM provides a lot of passes:

\begin{itemize}
\item try \texttt{\smaller opt -help}
\end{itemize}

\vfill
For performance reasons there are different kind of passes:

\begin{block}{LLVM Passes}
\input{img/01/llvm-passes.tex}
\centering
\end{block}
\end{frame}

\begin{frame}{LLVM Passes}
Each pass kind visits particular elements of a module:

\begin{description}[align=left, labelwidth=1cm]
\item[ImmutablePass] compiler configuration -- never run
\item[CallGraphSCCPass] post-order visit of CallGraph SCCs
\item[ModulePass] visit the whole module
\item[FunctionPass] visit functions
\item[LoopPass] post-order visit of loop nests
%\item[BasicBlockPass] visit basic blocks % DEPRECATED AND REMOVED
\item[RegionPass] visit a custom-defined region of code
\end{description}

\vfill
Specializations comes with restrictions:

\begin{itemize}
\item e.g. a \alert{FunctionPass} cannot add or delete functions
\item refer to ``Writing a LLVM Pass''~\cite{LOCAL:www/llvmWritingAPass}
      for accurate description of features and limitations of each kind of pass
\end{itemize}
\end{frame}

% \begin{frame}{Examples}
% Now we will see very simple passes:
%
% \begin{itemize}
% \item some of them are meaningless
% \item goal is to show you the LLVM API
% \end{itemize}
%
% \vfill
%
% The passes are:
% \begin{description}
% \item[instruction-count] simple instruction counting analysis
% \item[hello-llvm] optimization pass building an hello-world program
% \item[function-eraser] optimization pass removing ``small'' functions
% \end{description}
%
% \vfill
% Hint: take the LLVM pass writing tutorial~\cite{LOCAL:www/llvmWritingAPass}
% \end{frame}

\begin{frame}{What is Available Inside LLVM?}
LLVM provides passes performing basic transformations:

\begin{itemize}
\item variables promotion
\item loops canonicalization
\item \ldots
\end{itemize}

\vfill
They can be used to \alert{normalize/canonicalize} the input

\begin{itemize}
\item transform into a form analyzable for further passes
\item it is essential because keeps passes implementation manageable

\end{itemize}
\end{frame}

\section{LLVM-IR language}
\begin{frame}{LLVM IR}
LLVM IR~\cite{LOCAL:www/llvmLanguageRef} language is RISC-based:

\begin{itemize}
\item instructions operates on \alert{variables}~\footnote{Virtual registers}
\item only \llvminline{load} and \llvminline{store} access memory
\item \llvminline{alloca} used to reserve memory on function stacks
\end{itemize}
\vfill
There are also few \alert{high level instructions}:
\begin{itemize}
\item function call -- \llvminline{call}
\item pointer arithmetics -- \llvminline{getelementptr}
\item \ldots
\end{itemize}
\end{frame}

\begin{frame}{LLVM IR}{Types \& Variables}
LLVM IR is \alert{strongly typed}:

\begin{itemize}
\item e.g. you cannot assign a floating point value to an integer variable
without an explicit cast
\end{itemize}

\alert{Almost everything} is \alert{typed} -- e.g.:

\begin{description}
\item[functions] \llvminline{@fact} -- \llvminline{i32 (i32)}
\item[statements] \llvminline{\%3 = icmp eq i32 \%2, 0} -- \llvminline{i1}
\end{description}

A variable can be:

\begin{description}
\item[global] \llvminline{@var = common global i32 0, align 4}
\item[function parameter] \llvminline{define i32 @fact(i32 \%n)}
\item[local] \llvminline{\%2 = load i32, i32* \%1, align 4}
\end{description}

Local variables are defined by statements
\end{frame}

\begin{frame}{LLVM IR}{Example: factorial}

\begin{center}
\llvminput{snippet/01/fact.ll}
\end{center}
\end{frame}

\begin{frame}{LLVM IR Language}{Static Single Assignment}
LLVM IR is SSA-based:

\begin{itemize}
\item every variable is \alert{statically assigned} exactly \alert{once}
\end{itemize}

Statically means that:

\begin{itemize}
\item inside each function
\item for each variable \llvminline{\%foo}
\item there is only one statement in the form \llvminline{\%foo = ...}
\end{itemize}

Static is different from dynamic:

\begin{itemize}
\item a static assignment can be executed more than once
\end{itemize}
\end{frame}

\begin{frame}{Static Single Assignment}{Examples}
\begin{block}{Scalar SAXPY}
\centering
\cinput{snippet/02/scalar-saxpy.c}
\end{block}

\begin{block}{Scalar LLVM SAXPY}
\centering
\llvminput{snippet/02/scalar-saxpy.ll}
\end{block}

Temporary \llvminline{\%1} not reused! \llvminline{\%2} is used for the second
assignment!
\end{frame}

\begin{frame}{Static Single Assignment}{Examples}
\begin{block}{Array SAXPY}
\centering
\cinput{snippet/02/array-saxpy.c}
\end{block}

\begin{block}{Array LLVM SAXPY}
\centering
\llvminput{snippet/02/array-saxpy.ll}
\end{block}

One assignment for loop counter \llvminline{\%i.0}
\end{frame}

\begin{frame}{Static Single Assignment}{Handling Multiple Assignments}
\begin{block}{Max}
\centering
\cinput{snippet/02/max.c}
\end{block}

\begin{block}{LLVM Max -- Bad}
\centering
\llvminput{snippet/02/bad-max.ll}
\end{block}

Why is it bad?
\end{frame}

\begin{frame}{Static Single Assignment}{Use \llvminline{phi} to Avoid Troubles}
The \llvminline{\%2} variable must be statically set once

\begin{block}{LLVM Max}
\centering
\llvminput{snippet/02/good-max.ll}
\end{block}

The \llvminline{phi} instruction is a \emph{conditional move}:

\begin{itemize}
\item it takes $(variable_i, label_i)$ pairs
\item if coming from predecessor identified by $label_i$, its value is $variable_i$
\end{itemize}
\end{frame}

\begin{frame}{Static Single Assignment}{Definition and Uses}
Each SSA variable is set only once:

\begin{itemize}
\item variable \alert{definition}
\end{itemize}

\vfill
Each SSA variable can be used by multiple instructions:

\begin{itemize}
\item variable \alert{uses}
\end{itemize}

\vfill
Algorithms and technical language abuse of these terms:

\vfill
\emph{
Let \llvminline{\%foo} be a variable. If \llvminline{\%foo} definition has not
side-effects, and no uses, dead-code elimination can be efficiently performed
by erasing \llvminline{\%foo} definition from the CFG.
}
\end{frame}

\begin{frame}{Static Single Assignment}{Rationale}
Old compilers are not SSA-based:

\begin{itemize}
\item putting input into SSA-form is expensive
\item cost must be amortized
\end{itemize}

\vfill
New compilers are SSA-based:

\begin{itemize}
\item SSA easier to work with
\item SSA-based analysis/optimizations faster
\end{itemize}

\vfill
%All modern compilers are SSA-based:
%
%\begin{itemize}
%\item exception are old version of the HotSpot Client compiler
%\end{itemize}
\end{frame}

\section{Conclusions}
\begin{frame}{Conclusions}
LLVM is a \alert{production-quality} compiler framework:

\begin{itemize}
\item[$\Rightarrow$] impossible knowing all details
\end{itemize}

\vfill
But:

\begin{itemize}
\item it is well organized
\item given you known compilers theory, it is relatively easy to find what you need inside its sources
\end{itemize}

\vfill
Please take into account C++:
\begin{itemize}
\item basic skills required
\end{itemize}
\end{frame}

\section{Bibliography}
\begin{frame}[allowframebreaks]{Bibliography}
\nocite{*}
\bibliographystyle{unsrt}
\bibliography{bibliography}
\end{frame}
\end{document}
